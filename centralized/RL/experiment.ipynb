{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------- MODELO 1 -------------\n",
    "\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "model = DQN(\"MlpPolicy\", env, tensorboard_log=logdir, target_update_interval=1000)\n",
    "\n",
    "--> TRAIN\n",
    "{\n",
    "'accuracy': 0.8684, \n",
    "'precision': 0.6676653795716159, \n",
    "'recall': 0.7328348810011694,\n",
    "}\n",
    "\n",
    "--> TEST\n",
    "acc: 0.7110555555555556\n",
    "Precision: 0.61\n",
    "Recall: 0.57\n",
    "loss 0.643826319010477\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------- MODELO 2 --------------\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "model = DQN(\"MlpPolicy\", env, tensorboard_log=logdir, target_update_interval=1000, buffer_size=500000)\n",
    "\n",
    "--> TRAIN\n",
    " 'accuracy': 0.88081, \n",
    " 'precision': 0.6769016955434077, \n",
    " 'recall': 0.7302659856261807, \n",
    " \n",
    "--> TEST\n",
    "acc: 0.7087777777777777\n",
    "Precision: 0.65\n",
    "Recall: 0.46\n",
    "tempo de teste: 6.26\n",
    "loss 0.6311453665709996\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------ MODELO 3 --------------\n",
    "\n",
    "\n",
    "NOVA BASE\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "model = DQN(\"MlpPolicy\", env, tensorboard_log=logdir, target_update_interval=1000, buffer_size=100000)\n",
    "\n",
    "-> TRAIN\n",
    "{'accuracy': 0.80659, 'precision': 0.7074476782210595, \n",
    "'recall': 0.5189349644688315, 'terminated': True}\n",
    "\n",
    "-> TEST\n",
    "acc: 0.6869642857142857\n",
    "Precision: 0.61\n",
    "Recall: 0.54\n",
    "tempo de teste: 5.97\n",
    "loss 0.6535128001525802\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------- MODELO 4 ----------\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN\n",
    "\n",
    "'accuracy': 0.87778, 'precision': 0.7022845854894467, 'recall': 0.6538034841533987, Tempo de treinamento: 651.43\n",
    "\n",
    "\n",
    "-> TEST\n",
    "\n",
    "acc: 0.7390178571428572\n",
    "Precision: 0.61\n",
    "Recall: 0.67\n",
    "tempo de teste: 13.42\n",
    "loss 0.6401302111975632\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------- MODELO 5 ----------\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "model = DQN(\"MlpPolicy\", env, tensorboard_log=logdir, batch_size=128)\n",
    "\n",
    "-> TRAIN\n",
    "\n",
    "{'accuracy': 0.88776, \n",
    "'precision': 0.6990921283400392, \n",
    "'recall': 0.6772710463454369,\n",
    "Tempo de treinamento: 680.08\n",
    "}\n",
    "\n",
    "-> TEST\n",
    "\n",
    "Accuracy: 0.78\n",
    "Precision: 0.72\n",
    "Recall: 0.45\n",
    "tempo de teste: 13.83\n",
    "loss 0.5902731987869312\n",
    "acc: 0.7809375\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 6 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "\n",
    "'accuracy': 0.87276, 'precision': 0.9005626906060736, 'recall': 0.8382041338503978,\n",
    "\n",
    "-> TEST\n",
    "\n",
    "'accuracy': 0.8250446428571429, 'myacc': 0.8250446428571429, 'loss': 0.5816788868434167, 'precision': 0.88236529776284, 'recall': 0.7500892857142857, 'tempo': 5.255968809127808\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 8 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "{'step': 100000, 'idx': 10400, 'accuracy': 0.87664, 'precision': 0.8979768541983443, 'recall': 0.8499780114340543\n",
    "\n",
    "-> TEST\n",
    "{'accuracy': 0.8392857142857143, 'loss': 0.5775022290005638, 'precision': 0.8773584905660378, 'recall': 0.7888392857142857, 'test_time': 4.584730625152588}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 9 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.2\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "{'step': 100000, 'idx': 10400, 'accuracy': 0.88034, 'precision': 0.8986509133567957, 'recall': 0.8575140926718107,\n",
    "\n",
    "-> TEST\n",
    "'accuracy': 0.8204910714285715, 'loss': 0.5856501450665781, 'precision': 0.8648978347057029, 'recall': 0.7596428571428572\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 10 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.1\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "{'step': 100000, 'idx': 10400, 'accuracy': 0.87766, 'precision': 0.8998645674623328, 'recall': 0.8500379802502699\n",
    "\n",
    "-> TEST\n",
    "{'accuracy': 0.83, 'loss': 0.5795819283610076, 'precision': 0.8853211009174312, 'recall': 0.7582142857142857, 'test_time': 4.427851438522339}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 11 -----\n",
    "\n",
    "TIMESTEPS = 90000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.1\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "ruim\n",
    "\n",
    "-> TEST\n",
    "ruim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 11 -----\n",
    "\n",
    "TIMESTEPS = 120000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.1\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "ruim\n",
    "\n",
    "-> TEST\n",
    "ruim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 11 -----\n",
    "\n",
    "TIMESTEPS = 120000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.1\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir)\n",
    "\n",
    "-> TRAIN \n",
    "ruim\n",
    "\n",
    "-> TEST\n",
    "ruim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 11 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.1\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir, learning_rate= 0,00005)\n",
    "\n",
    "-> TRAIN \n",
    "{'step': 100000, 'idx': 10400, 'accuracy': 0.84811, 'precision': 0.9087602374862132, 'recall': 0.7740974693159557\n",
    "\n",
    "-> TEST\n",
    "{'accuracy': 0.8533928571428572, 'loss': 0.5735587653414478, 'precision': 0.8716431924882629, 'recall': 0.8288392857142857\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 12 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.15\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir, learning_rate= 0,00005)\n",
    "\n",
    "-> TRAIN \n",
    "'step': 100000, 'idx': 10400, 'accuracy': 0.84811, 'precision': 0.9087602374862132, 'recall': 0.7740974693159557\n",
    "\n",
    "-> TEST\n",
    "'accuracy': 0.8533928571428572, 'loss': 0.5735587653414478, 'precision': 0.8716431924882629, 'recall': 0.8288392857142857\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 13 -----\n",
    "\n",
    "TIMESTEPS = 100000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.15\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir, learning_rate= 3e-5)\n",
    "\n",
    "----- TRAIN ------\n",
    "{'step': 100000, 'idx': 10400, 'accuracy': 0.81671, 'precision': 0.9195277549831908, 'recall': 0.6943789229600608, 'terminated': False, \n",
    "\n",
    "----- TEST ------\n",
    "{'accuracy': 0.7283928571428572, 'loss': 0.6408740701293287, 'precision': 0.7215102182196051, 'recall': 0.7439285714285714, 'test_time': 6.380535840988159}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----- MODELO 13 -----\n",
    "\n",
    "TIMESTEPS = 180000\n",
    "100 rows per episode\n",
    "reward por falso negativo = -1.15\n",
    "model = DQN(\"MlpPolicy\", train_env, tensorboard_log=logdir, learning_rate= 5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
